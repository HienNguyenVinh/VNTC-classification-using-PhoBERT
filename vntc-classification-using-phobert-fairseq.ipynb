{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eba2b72",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-07T08:10:56.775741Z",
     "iopub.status.busy": "2024-03-07T08:10:56.775381Z",
     "iopub.status.idle": "2024-03-07T08:12:50.416881Z",
     "shell.execute_reply": "2024-03-07T08:12:50.415642Z"
    },
    "papermill": {
     "duration": 113.65558,
     "end_time": "2024-03-07T08:12:50.419334",
     "exception": false,
     "start_time": "2024-03-07T08:10:56.763754",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fairseq\r\n",
      "  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\r\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: cffi in /opt/conda/lib/python3.10/site-packages (from fairseq) (1.16.0)\r\n",
      "Requirement already satisfied: cython in /opt/conda/lib/python3.10/site-packages (from fairseq) (3.0.8)\r\n",
      "Collecting hydra-core<1.1,>=1.0.7 (from fairseq)\r\n",
      "  Downloading hydra_core-1.0.7-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "Collecting omegaconf<2.1 (from fairseq)\r\n",
      "  Downloading omegaconf-2.0.6-py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from fairseq) (2023.12.25)\r\n",
      "Collecting sacrebleu>=1.4.12 (from fairseq)\r\n",
      "  Downloading sacrebleu-2.4.0-py3-none-any.whl.metadata (57 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from fairseq) (2.1.2)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from fairseq) (4.66.1)\r\n",
      "Collecting bitarray (from fairseq)\r\n",
      "  Downloading bitarray-2.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\r\n",
      "Requirement already satisfied: torchaudio>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from fairseq) (2.1.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from fairseq) (1.24.4)\r\n",
      "Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq)\r\n",
      "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.1.* in /opt/conda/lib/python3.10/site-packages (from omegaconf<2.1->fairseq) (6.0.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from omegaconf<2.1->fairseq) (4.9.0)\r\n",
      "Collecting portalocker (from sacrebleu>=1.4.12->fairseq)\r\n",
      "  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\r\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq) (0.9.0)\r\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq) (0.4.6)\r\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq) (5.1.0)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi->fairseq) (2.21)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->fairseq) (3.13.1)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->fairseq) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->fairseq) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->fairseq) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->fairseq) (2023.12.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->fairseq) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->fairseq) (1.3.0)\r\n",
      "Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\r\n",
      "Downloading sacrebleu-2.4.0-py3-none-any.whl (106 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading bitarray-2.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.3/288.3 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\r\n",
      "Building wheels for collected packages: fairseq, antlr4-python3-runtime\r\n",
      "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=10416035 sha256=8661847e97d0b4286bf22c0804f120139a0a80e37a121956ddc48317dd204e64\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/e4/35/55/9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\r\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141210 sha256=f0a45e5aa89183cc290f6acf9085aa7876bd9602dbbf1fb60098f3068ec4f862\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\r\n",
      "Successfully built fairseq antlr4-python3-runtime\r\n",
      "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\r\n",
      "\u001b[0mInstalling collected packages: bitarray, antlr4-python3-runtime, portalocker, omegaconf, sacrebleu, hydra-core, fairseq\r\n",
      "Successfully installed antlr4-python3-runtime-4.8 bitarray-2.9.2 fairseq-0.12.2 hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.8.2 sacrebleu-2.4.0\r\n",
      "Collecting fastbpe\r\n",
      "  Downloading fastBPE-0.1.0.tar.gz (35 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25hBuilding wheels for collected packages: fastbpe\r\n",
      "  Building wheel for fastbpe (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for fastbpe: filename=fastBPE-0.1.0-cp310-cp310-linux_x86_64.whl size=73470 sha256=25d65249d93864daf710b91b65ee4e3500c757ba110e003eb879d1cfa6aa24ab\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/13/5d/b9/4b8897941ebc9e8c6cc3f3ffd3ea5115731754269205098754\r\n",
      "Successfully built fastbpe\r\n",
      "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\r\n",
      "\u001b[0mInstalling collected packages: fastbpe\r\n",
      "Successfully installed fastbpe-0.1.0\r\n",
      "Collecting vncorenlp\r\n",
      "  Downloading vncorenlp-1.0.3.tar.gz (2.6 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from vncorenlp) (2.31.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->vncorenlp) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->vncorenlp) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->vncorenlp) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->vncorenlp) (2023.11.17)\r\n",
      "Building wheels for collected packages: vncorenlp\r\n",
      "  Building wheel for vncorenlp (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-py3-none-any.whl size=2645932 sha256=c4609ea56398d8ab1853d4b24e2fe02d41784728ef7a756fe9aa71cb745986bc\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/5d/d9/b3/41f6c6b1ab758561fd4aab55dc0480b9d7a131c6aaa573a3fa\r\n",
      "Successfully built vncorenlp\r\n",
      "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\r\n",
      "\u001b[0mInstalling collected packages: vncorenlp\r\n",
      "Successfully installed vncorenlp-1.0.3\r\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.37.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.1)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\r\n",
      "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install fairseq\n",
    "!pip install fastbpe\n",
    "!pip install vncorenlp\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e16418",
   "metadata": {
    "papermill": {
     "duration": 0.015873,
     "end_time": "2024-03-07T08:12:50.451823",
     "exception": false,
     "start_time": "2024-03-07T08:12:50.435950",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* fairseq: proj của Fb chuyên hỗ trợ các nghiên cứu và dự án liên quan đến model seq2seq\n",
    "* fastBPE: package hỗ trợ tokenize word thành các subword\n",
    "* vncorenlp: package NLP trong tiếng Việt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f4d538",
   "metadata": {
    "papermill": {
     "duration": 0.015781,
     "end_time": "2024-03-07T08:12:50.484653",
     "exception": false,
     "start_time": "2024-03-07T08:12:50.468872",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Download pre-trained model PhoBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bddd405",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T08:12:50.519042Z",
     "iopub.status.busy": "2024-03-07T08:12:50.518677Z",
     "iopub.status.idle": "2024-03-07T08:13:58.305745Z",
     "shell.execute_reply": "2024-03-07T08:13:58.304786Z"
    },
    "papermill": {
     "duration": 67.806534,
     "end_time": "2024-03-07T08:13:58.307892",
     "exception": false,
     "start_time": "2024-03-07T08:12:50.501358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-07 08:12:51--  https://public.vinai.io/PhoBERT_base_fairseq.tar.gz\r\n",
      "Resolving public.vinai.io (public.vinai.io)... 52.84.162.15, 52.84.162.17, 52.84.162.36, ...\r\n",
      "Connecting to public.vinai.io (public.vinai.io)|52.84.162.15|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 1243308020 (1.2G) [application/x-tar]\r\n",
      "Saving to: 'PhoBERT_base_fairseq.tar.gz'\r\n",
      "\r\n",
      "PhoBERT_base_fairse 100%[===================>]   1.16G  23.5MB/s    in 52s     \r\n",
      "\r\n",
      "2024-03-07 08:13:44 (22.8 MB/s) - 'PhoBERT_base_fairseq.tar.gz' saved [1243308020/1243308020]\r\n",
      "\r\n",
      "PhoBERT_base_fairseq/\r\n",
      "PhoBERT_base_fairseq/bpe.codes\r\n",
      "PhoBERT_base_fairseq/model.pt\r\n",
      "PhoBERT_base_fairseq/dict.txt\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://public.vinai.io/PhoBERT_base_fairseq.tar.gz\n",
    "!tar -xzvf PhoBERT_base_fairseq.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f361a312",
   "metadata": {
    "papermill": {
     "duration": 0.028439,
     "end_time": "2024-03-07T08:13:58.365756",
     "exception": false,
     "start_time": "2024-03-07T08:13:58.337317",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79ca842d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T08:13:58.425460Z",
     "iopub.status.busy": "2024-03-07T08:13:58.425137Z",
     "iopub.status.idle": "2024-03-07T08:14:45.394228Z",
     "shell.execute_reply": "2024-03-07T08:14:45.393426Z"
    },
    "papermill": {
     "duration": 47.001508,
     "end_time": "2024-03-07T08:14:45.396547",
     "exception": false,
     "start_time": "2024-03-07T08:13:58.395039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-07 08:14:05.075089: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-07 08:14:05.075220: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-07 08:14:05.211760: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "1042301B [00:00, 28610031.50B/s]\n",
      "456318B [00:00, 15492944.67B/s]\n"
     ]
    }
   ],
   "source": [
    "from fairseq.models.roberta import RobertaModel\n",
    "phoBERT = RobertaModel.from_pretrained('PhoBERT_base_fairseq', checkpoint_file='model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45274be",
   "metadata": {
    "papermill": {
     "duration": 0.030225,
     "end_time": "2024-03-07T08:14:45.459045",
     "exception": false,
     "start_time": "2024-03-07T08:14:45.428820",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BPE Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b6bd773",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T08:14:45.519223Z",
     "iopub.status.busy": "2024-03-07T08:14:45.518870Z",
     "iopub.status.idle": "2024-03-07T08:14:45.606974Z",
     "shell.execute_reply": "2024-03-07T08:14:45.605896Z"
    },
    "papermill": {
     "duration": 0.120726,
     "end_time": "2024-03-07T08:14:45.609154",
     "exception": false,
     "start_time": "2024-03-07T08:14:45.488428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens list:  tensor([    0, 11623, 31433,   453,    52,   480,  2429,    54,    45,  2080,\n",
      "         5922,  8121,     2])\n",
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading codes from PhoBERT_base_fairseq/bpe.codes ...\n",
      "Read 64000 codes from the codes file.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Tôn Ngộ Không đang đánh răng thì bị Đường Tăng gõ'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fairseq.data.encoders.fastbpe import fastBPE\n",
    "\n",
    "class BPE():\n",
    "    bpe_codes = 'PhoBERT_base_fairseq/bpe.codes'\n",
    "\n",
    "args = BPE()\n",
    "phoBERT.bpe = fastBPE(args)\n",
    "\n",
    "# example:\n",
    "tokens = phoBERT.encode('Tôn Ngộ Không đang đánh răng thì bị Đường Tăng gõ')\n",
    "print('Tokens list: ', tokens)\n",
    "print(len(tokens))  # BERT tự thêm các ký tự <s> và </s> đánh dấu start và end của câu \n",
    "\n",
    "phoBERT.decode(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8411c6f6",
   "metadata": {
    "papermill": {
     "duration": 0.029338,
     "end_time": "2024-03-07T08:14:45.668561",
     "exception": false,
     "start_time": "2024-03-07T08:14:45.639223",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Extract features từ RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4149d598",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T08:14:45.728617Z",
     "iopub.status.busy": "2024-03-07T08:14:45.728314Z",
     "iopub.status.idle": "2024-03-07T08:14:45.991172Z",
     "shell.execute_reply": "2024-03-07T08:14:45.990199Z"
    },
    "papermill": {
     "duration": 0.29532,
     "end_time": "2024-03-07T08:14:45.993390",
     "exception": false,
     "start_time": "2024-03-07T08:14:45.698070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token size:  torch.Size([13])\n",
      "size of last layer:  torch.Size([1, 13, 768])\n",
      "number layer in all layers:  13\n",
      "Last layer features:  tensor([[[False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]]])\n"
     ]
    }
   ],
   "source": [
    "# Extract the last layer's features\n",
    "last_layer_features = phoBERT.extract_features(tokens)\n",
    "# assert last_layer_features.size() == torch.Size([1, 5, 1024])\n",
    "print('token size: ', tokens.size())\n",
    "print('size of last layer: ', last_layer_features.size())\n",
    "\n",
    "# Extract all layer's features (layer 0 is the embedding layer)\n",
    "all_layers = phoBERT.extract_features(tokens, return_all_hiddens=True)\n",
    "print('number layer in all layers: ', len(all_layers))\n",
    "\n",
    "# last_layer_features must equal to last layer in all_layers:\n",
    "print('Last layer features: ', all_layers[-1] == last_layer_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d011402a",
   "metadata": {
    "papermill": {
     "duration": 0.029391,
     "end_time": "2024-03-07T08:14:46.052790",
     "exception": false,
     "start_time": "2024-03-07T08:14:46.023399",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Filling mask\n",
    "- Download package VnCoreNLP để tokenize các sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f72973a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T08:14:46.113172Z",
     "iopub.status.busy": "2024-03-07T08:14:46.112807Z",
     "iopub.status.idle": "2024-03-07T08:14:54.761945Z",
     "shell.execute_reply": "2024-03-07T08:14:54.760441Z"
    },
    "papermill": {
     "duration": 8.682144,
     "end_time": "2024-03-07T08:14:54.764504",
     "exception": false,
     "start_time": "2024-03-07T08:14:46.082360",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-07 08:14:47--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 27412575 (26M) [application/octet-stream]\r\n",
      "Saving to: 'VnCoreNLP-1.1.1.jar'\r\n",
      "\r\n",
      "VnCoreNLP-1.1.1.jar 100%[===================>]  26.14M  --.-KB/s    in 0.1s    \r\n",
      "\r\n",
      "2024-03-07 08:14:49 (209 MB/s) - 'VnCoreNLP-1.1.1.jar' saved [27412575/27412575]\r\n",
      "\r\n",
      "--2024-03-07 08:14:50--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 526544 (514K) [application/octet-stream]\r\n",
      "Saving to: 'vi-vocab'\r\n",
      "\r\n",
      "vi-vocab            100%[===================>] 514.20K  --.-KB/s    in 0.03s   \r\n",
      "\r\n",
      "2024-03-07 08:14:50 (18.7 MB/s) - 'vi-vocab' saved [526544/526544]\r\n",
      "\r\n",
      "--2024-03-07 08:14:51--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 128508 (125K) [text/plain]\r\n",
      "Saving to: 'wordsegmenter.rdr'\r\n",
      "\r\n",
      "wordsegmenter.rdr   100%[===================>] 125.50K  --.-KB/s    in 0.01s   \r\n",
      "\r\n",
      "2024-03-07 08:14:51 (9.29 MB/s) - 'wordsegmenter.rdr' saved [128508/128508]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p vncorenlp/models/wordsegmenter\n",
    "!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n",
    "!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n",
    "!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n",
    "!mv VnCoreNLP-1.1.1.jar vncorenlp/ \n",
    "!mv vi-vocab vncorenlp/models/wordsegmenter/\n",
    "!mv wordsegmenter.rdr vncorenlp/models/wordsegmenter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a6e8240",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T08:14:54.828697Z",
     "iopub.status.busy": "2024-03-07T08:14:54.828348Z",
     "iopub.status.idle": "2024-03-07T08:15:00.208794Z",
     "shell.execute_reply": "2024-03-07T08:15:00.207927Z"
    },
    "papermill": {
     "duration": 5.414375,
     "end_time": "2024-03-07T08:15:00.211070",
     "exception": false,
     "start_time": "2024-03-07T08:14:54.796695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tôn_Ngộ_Không đang  <mask> răng thì bị Đường Tăng gõ\n"
     ]
    }
   ],
   "source": [
    "from vncorenlp import VnCoreNLP\n",
    "rdrsegmenter = VnCoreNLP(\"vncorenlp/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx500m')\n",
    "\n",
    "text = 'Tôn Ngộ Không đang đánh răng thì bị Đường Tăng gõ'\n",
    "\n",
    "# Tokenizer câu gốc và thay từ 'đánh' = <mask>\n",
    "words = rdrsegmenter.tokenize(text)[0]\n",
    "for i, token in enumerate(words):\n",
    "    if token == 'đánh':\n",
    "        words[i] = ' <mask>'\n",
    "text_masked = ' '.join(words)\n",
    "print(text_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f134de55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T08:15:00.274566Z",
     "iopub.status.busy": "2024-03-07T08:15:00.274255Z",
     "iopub.status.idle": "2024-03-07T08:15:00.405810Z",
     "shell.execute_reply": "2024-03-07T08:15:00.404388Z"
    },
    "papermill": {
     "duration": 0.165061,
     "end_time": "2024-03-07T08:15:00.407887",
     "exception": false,
     "start_time": "2024-03-07T08:15:00.242826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total probability:  [0.7018280029296875, 0.07104982435703278, 0.06327974051237106, 0.043107498437166214, 0.008277255110442638, 0.00821719691157341, 0.007822426036000252, 0.006525953765958548, 0.006412186659872532, 0.005651082377880812]\n",
      "Tôn_Ngộ_Không đang đánh răng thì bị Đường Tăng gõ\n",
      "Tôn_Ngộ_Không đang nhổ răng thì bị Đường Tăng gõ\n",
      "Tôn_Ngộ_Không đang chải răng thì bị Đường Tăng gõ\n",
      "Tôn_Ngộ_Không đang xỉa răng thì bị Đường Tăng gõ\n",
      "Tôn_Ngộ_Không đang nhe răng thì bị Đường Tăng gõ\n",
      "Tôn_Ngộ_Không đang nghiến răng thì bị Đường Tăng gõ\n",
      "Tôn_Ngộ_Không đang sửa răng thì bị Đường Tăng gõ\n",
      "Tôn_Ngộ_Không đang niềng răng thì bị Đường Tăng gõ\n",
      "Tôn_Ngộ_Không đang khám răng thì bị Đường Tăng gõ\n",
      "Tôn_Ngộ_Không đang mài răng thì bị Đường Tăng gõ\n"
     ]
    }
   ],
   "source": [
    "# Timf 10 từ thích hợp với <mask>\n",
    "import numpy as np\n",
    "\n",
    "top_filled_words = phoBERT.fill_mask(text_masked, topk=10)\n",
    "topk_probs = [item[1] for item in top_filled_words]\n",
    "\n",
    "print('Total probability: ', topk_probs)\n",
    "for i, output in enumerate(top_filled_words):\n",
    "    print(output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d466346d",
   "metadata": {
    "papermill": {
     "duration": 0.030471,
     "end_time": "2024-03-07T08:15:00.469737",
     "exception": false,
     "start_time": "2024-03-07T08:15:00.439266",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7abd659",
   "metadata": {
    "papermill": {
     "duration": 0.030552,
     "end_time": "2024-03-07T08:15:00.530609",
     "exception": false,
     "start_time": "2024-03-07T08:15:00.500057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Chuẩn bị dữ liệu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95c728df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T08:15:00.638050Z",
     "iopub.status.busy": "2024-03-07T08:15:00.637097Z",
     "iopub.status.idle": "2024-03-07T08:15:21.766771Z",
     "shell.execute_reply": "2024-03-07T08:15:21.765633Z"
    },
    "papermill": {
     "duration": 21.207728,
     "end_time": "2024-03-07T08:15:21.769028",
     "exception": false,
     "start_time": "2024-03-07T08:15:00.561300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'VNTC'...\r\n",
      "remote: Enumerating objects: 39, done.\u001b[K\r\n",
      "remote: Total 39 (delta 0), reused 0 (delta 0), pack-reused 39\u001b[K\r\n",
      "Unpacking objects: 100% (39/39), 160.90 MiB | 10.87 MiB/s, done.\r\n",
      "Updating files: 100% (15/15), done.\r\n",
      "Filtering content: 100% (2/2), 168.95 MiB | 61.07 MiB/s, done.\r\n",
      "Stats.txt  Test_Full.rar  Train_Full.rar\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/duyvuleo/VNTC.git\n",
    "!ls VNTC/Data/10Topics/Ver1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d1fd831",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T08:15:21.837252Z",
     "iopub.status.busy": "2024-03-07T08:15:21.836874Z",
     "iopub.status.idle": "2024-03-07T08:15:27.890452Z",
     "shell.execute_reply": "2024-03-07T08:15:27.889338Z"
    },
    "papermill": {
     "duration": 6.090825,
     "end_time": "2024-03-07T08:15:27.892672",
     "exception": false,
     "start_time": "2024-03-07T08:15:21.801847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/VNTC/Data/10Topics/Ver1.1\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "The following NEW packages will be installed:\r\n",
      "  unrar\r\n",
      "0 upgraded, 1 newly installed, 0 to remove and 30 not upgraded.\r\n",
      "Need to get 113 kB of archives.\r\n",
      "After this operation, 406 kB of additional disk space will be used.\r\n",
      "Get:1 http://archive.ubuntu.com/ubuntu focal/multiverse amd64 unrar amd64 1:5.6.6-2build1 [113 kB]\r\n",
      "Fetched 113 kB in 0s (308 kB/s)\r\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package unrar.\r\n",
      "(Reading database ... 113807 files and directories currently installed.)\r\n",
      "Preparing to unpack .../unrar_1%3a5.6.6-2build1_amd64.deb ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 20%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Unpacking unrar (1:5.6.6-2build1) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 40%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Setting up unrar (1:5.6.6-2build1) ...\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 60%]\u001b[49m\u001b[39m [##################################........................] \u001b8update-alternatives: using /usr/bin/unrar-nonfree to provide /usr/bin/unrar (unrar) in auto mode\r\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/unrar.1.gz because associated file /usr/share/man/man1/unrar-nonfree.1.gz (of link group unrar) doesn't exist\r\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 80%]\u001b[49m\u001b[39m [##############################################............] \u001b8Processing triggers for man-db (2.9.1-1) ...\r\n",
      "\r\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/VNTC/Data/10Topics/Ver1.1\n",
    "!apt install unrar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "617916a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T08:15:27.965362Z",
     "iopub.status.busy": "2024-03-07T08:15:27.965023Z",
     "iopub.status.idle": "2024-03-07T08:15:47.489987Z",
     "shell.execute_reply": "2024-03-07T08:15:47.489006Z"
    },
    "papermill": {
     "duration": 19.56425,
     "end_time": "2024-03-07T08:15:47.492305",
     "exception": false,
     "start_time": "2024-03-07T08:15:27.928055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n",
      "PhoBERT_base_fairseq\t     Test_Full\t VNTC\t\t     vncorenlp\r\n",
      "PhoBERT_base_fairseq.tar.gz  Train_Full  __notebook__.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!unrar x Test_Full.rar /kaggle/working > /dev/null\n",
    "!unrar x Train_Full.rar /kaggle/working > /dev/null\n",
    "%cd /kaggle/working\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2abb83",
   "metadata": {
    "papermill": {
     "duration": 0.03466,
     "end_time": "2024-03-07T08:15:47.562464",
     "exception": false,
     "start_time": "2024-03-07T08:15:47.527804",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Đọc dữ liệu từ file .txt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69d8d6a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T08:15:47.634791Z",
     "iopub.status.busy": "2024-03-07T08:15:47.633931Z",
     "iopub.status.idle": "2024-03-07T08:33:23.786358Z",
     "shell.execute_reply": "2024-03-07T08:33:23.785449Z"
    },
    "papermill": {
     "duration": 1056.227435,
     "end_time": "2024-03-07T08:33:23.824656",
     "exception": false,
     "start_time": "2024-03-07T08:15:47.597221",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [06:55, 37.79s/it]\n",
      "11it [10:40, 58.22s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_path = '/kaggle/working/Train_Full'\n",
    "test_path = '/kaggle/working/Test_Full'\n",
    "\n",
    "def read_txt(path):\n",
    "    with open(path, 'r', encoding='utf-16') as f:\n",
    "        data = f.read()\n",
    "    return data\n",
    "\n",
    "def make_data(root_path):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    \n",
    "    for root, dirs, files in tqdm(os.walk(root_path)):\n",
    "        for file_name in files:\n",
    "            try:\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                content = read_txt(file_path)\n",
    "                \n",
    "                # Tokenize word\n",
    "                content = rdrsegmenter.tokenize(content)\n",
    "                content = \" \".join([' '.join(x) for x in content])\n",
    "                label = root.split(os.path.sep)[-1] \n",
    "                texts.append(content)\n",
    "                labels.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_path}: {e}\")\n",
    "    \n",
    "    return texts, labels\n",
    "\n",
    "text_train, label_train = make_data(train_path)\n",
    "text_test, label_test = make_data(test_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20e67988",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T08:33:23.899585Z",
     "iopub.status.busy": "2024-03-07T08:33:23.898783Z",
     "iopub.status.idle": "2024-03-07T08:33:23.903883Z",
     "shell.execute_reply": "2024-03-07T08:33:23.903006Z"
    },
    "papermill": {
     "duration": 0.044697,
     "end_time": "2024-03-07T08:33:23.905895",
     "exception": false,
     "start_time": "2024-03-07T08:33:23.861198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“ Má Blanche ” \" Má Blanche \" với trẻ mồ_côi Haiti Khi ôm_ấp một đứa trẻ tàn_tật trong một cô_nhi_viện mà cô thành_lập ở Haiti , Susie_Krabacher luôn nhớ lại cuộc_sống ngập_ngụa ma_tuý , nghề làm người_mẫu cho tạp_chí khiêu_dâm Playboy và nỗi đau của một tuổi_thơ bị lạm_dụng . “ Đó là một quãng thời_gian sống khác . Đây mới là việc tôi thật_sự muốn làm ” – Krabacher nói . 42 tuổi , tóc vàng , thân_hình “ bốc_lửa ” , nổi_bật ở một đất_nước đa_số là người da đen , Krabacher với biệt_danh là “ Má Blanche ” nói_chuyện thoải_mái về cuộc_đời mình . Chào_đời ở Alabama , Krabacher bị một người_thân lạm_dụng thân_xác lúc còn bé , sau đó được nhận làm con_nuôi đến lúc 12 tuổi . Cô sống tự_lập lúc 16 tuổi , cố_gắng kiếm sống ở nhà_hàng và làm tiếp_tân văn_phòng . Một năm sau đó , một người bạn gửi bức ảnh của Krabacher cho tạp_chí Playboy . “ Tôi đã trở_thành người chụp ảnh bìa cho Playboy vào lúc 20 tuổi ( năm 1983 ) ” – Krabacher nhớ lại . Năm năm sau , Krabacher nhận thấy kiểu sống gấp của mình không có ý_nghĩa và bắt_đầu tìm_kiếm một cái gì khác_biệt trong đời . Sau đó cô_lập gia_đình với một luật_sư ở Aspen , bang Colorado ( Mỹ ) , mở một cửa_hàng bán đồ_cổ và đầu_tư vào một nhà_hàng . Krabacher tâm_sự : “ Khi còn bé tôi đã hứa với Thượng_đế rằng nếu ngài không khiến tôi phải chết , tôi sẽ giúp_đỡ trẻ_em ” . Krabacher bắt_đầu tạo_dựng giấc mơ của mình ở Mông_Cổ vào năm 1994 , nhưng một người quen hỏi cô sao phải đi quá xa , trong khi đất_nước Haiti đầy sóng_gió ở gần cần được giúp_đỡ nhiều hơn . Krabacher nhanh_chóng thu_xếp một chuyến đi và trải qua đêm đầu_tiên ở Thành_phố Mặt_trời , một khu_vực tồi_tàn nằm ở ven biển Port-au-Prince - nơi cư_ngụ của những người nghèo nhất Haiti và gần đây là chiến_trường giữa những người gìn_giữ hoà_bình Liên_Hiệp_Quốc và các nhóm nổi_loạn . Quỹ_Mercy & amp ; Sharing ở Aspen , bang Colorado , do Krabacher và chồng sáng_lập vào năm 1995 có 3 cô_nhi_viện , 6 trường_học , 1 bệnh_viện và 6 chương_trình cấp_dưỡng ở Haiti . Các cô_nhi_viện là nhà của 120 trẻ và quỹ của vợ_chồng Krabacher cung_cấp 3.300 USD / ngày từ ngân_sách quyên_góp hằng năm khoảng 400.000 USD đến 700.000 USD dưới dạng thực_phẩm , tã_lót và các đồ tiếp_tế khác . Krabacher , người thường_xuyên dành thời_gian ở Haiti , cho biết cô muốn được chết ở Haiti , nhưng “ hy_vọng không phải vì một viên đạn ” , để chăm_sóc những đứa trẻ bất_hạnh . The gioi\n",
      "33759 50373\n"
     ]
    }
   ],
   "source": [
    "print(text_train[0], label_train[0])\n",
    "print(len(text_train), len(text_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231a1304",
   "metadata": {
    "papermill": {
     "duration": 0.036724,
     "end_time": "2024-03-07T08:33:23.979104",
     "exception": false,
     "start_time": "2024-03-07T08:33:23.942380",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Encode các labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b954409f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T08:33:24.055574Z",
     "iopub.status.busy": "2024-03-07T08:33:24.054923Z",
     "iopub.status.idle": "2024-03-07T08:33:24.821875Z",
     "shell.execute_reply": "2024-03-07T08:33:24.820674Z"
    },
    "papermill": {
     "duration": 0.808365,
     "end_time": "2024-03-07T08:33:24.823993",
     "exception": false,
     "start_time": "2024-03-07T08:33:24.015628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chinh tri Xa hoi' 'Doi song' 'Khoa hoc' 'Kinh doanh' 'Phap luat'\n",
      " 'Suc khoe' 'The gioi' 'The thao' 'Van hoa' 'Vi tinh']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lb_encoder = LabelEncoder()\n",
    "label_train_encoded = lb_encoder.fit_transform(label_train)\n",
    "label_test_encoded = lb_encoder.transform(label_test)\n",
    "\n",
    "print(lb_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70ab8b8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T08:33:24.901094Z",
     "iopub.status.busy": "2024-03-07T08:33:24.900045Z",
     "iopub.status.idle": "2024-03-07T08:33:25.012523Z",
     "shell.execute_reply": "2024-03-07T08:33:25.011760Z"
    },
    "papermill": {
     "duration": 0.152951,
     "end_time": "2024-03-07T08:33:25.014671",
     "exception": false,
     "start_time": "2024-03-07T08:33:24.861720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Chia tập train thành tập train và valid\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(text_train, label_train_encoded, test_size=0.1, stratify=label_train_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f99d6ba",
   "metadata": {
    "papermill": {
     "duration": 0.036824,
     "end_time": "2024-03-07T08:33:25.089700",
     "exception": false,
     "start_time": "2024-03-07T08:33:25.052876",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Tokenizer các câu và padding về cùng độ dài**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b0ebf08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T08:33:25.165157Z",
     "iopub.status.busy": "2024-03-07T08:33:25.164812Z",
     "iopub.status.idle": "2024-03-07T08:33:25.390664Z",
     "shell.execute_reply": "2024-03-07T08:33:25.389754Z"
    },
    "papermill": {
     "duration": 0.266015,
     "end_time": "2024-03-07T08:33:25.392773",
     "exception": false,
     "start_time": "2024-03-07T08:33:25.126758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading codes from /kaggle/working/PhoBERT_base_fairseq/bpe.codes ...\n",
      "Read 64000 codes from the codes file.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from fairseq.data.encoders.fastbpe import fastBPE\n",
    "from fairseq.data import Dictionary\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--bpe-codes',\n",
    "                    default=\"/kaggle/working/PhoBERT_base_fairseq/bpe.codes\",\n",
    "                    required=False,\n",
    "                    type=str,\n",
    "                    help='path to fastBPE BPE'\n",
    ")\n",
    "args, unknown = parser.parse_known_args()\n",
    "bpe = fastBPE(args)\n",
    "\n",
    "\n",
    "# Load dictionary\n",
    "vocab = Dictionary()\n",
    "vocab.add_from_file(\"/kaggle/working/PhoBERT_base_fairseq/dict.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d68ff243",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T08:33:25.468596Z",
     "iopub.status.busy": "2024-03-07T08:33:25.468279Z",
     "iopub.status.idle": "2024-03-07T08:33:25.472946Z",
     "shell.execute_reply": "2024-03-07T08:33:25.472148Z"
    },
    "papermill": {
     "duration": 0.044373,
     "end_time": "2024-03-07T08:33:25.474746",
     "exception": false,
     "start_time": "2024-03-07T08:33:25.430373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# max_sequence_length = 256\n",
    "\n",
    "# def convert_lines(lines, vocab, bpe):\n",
    "#     '''\n",
    "#       lines: list các văn bản input\n",
    "#       vocab: từ điển dùng để encoding subwords\n",
    "#     '''\n",
    "#     # Khởi tạo ma trận ouput\n",
    "#     outputs = np.zeros((len(lines), max_sequence_length))\n",
    "#     cls_id = 0\n",
    "#     eos_id = 2\n",
    "#     pad_id = 1\n",
    "    \n",
    "#     for ids, row in tqdm(enumerate(lines), total=len(lines)):\n",
    "#         # Mã hóa subwords theo bpe\n",
    "#         subwords = bpe.encode('<s>' + row + ' </s>')\n",
    "#         input_ids = vocab.encode_line(subwords, append_eos=False, add_if_not_exist=False).long().tolist()\n",
    "        \n",
    "#         # Cắt input nếu độ dài vượt quá max_sequence_length\n",
    "#         if len(input_ids) > max_sequence_length:\n",
    "#             input_ids = input_ids[:max_sequence_length]\n",
    "#             input_ids[-1] = eos_id\n",
    "#         else:\n",
    "#             input_ids = input_ids + [pad_id, ] * (max_sequence_length - len(input_ids))\n",
    "        \n",
    "#         outputs[ids, :] = np.array(input_ids)\n",
    "#     return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a862fd90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T08:33:25.549833Z",
     "iopub.status.busy": "2024-03-07T08:33:25.549536Z",
     "iopub.status.idle": "2024-03-07T08:40:11.854430Z",
     "shell.execute_reply": "2024-03-07T08:40:11.853307Z"
    },
    "papermill": {
     "duration": 406.345428,
     "end_time": "2024-03-07T08:40:11.856963",
     "exception": false,
     "start_time": "2024-03-07T08:33:25.511535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30383/30383 [02:20<00:00, 215.79it/s]\n",
      "100%|██████████| 3376/3376 [00:15<00:00, 211.24it/s]\n",
      "100%|██████████| 50373/50373 [04:06<00:00, 203.95it/s]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import torch\n",
    "\n",
    "MAX_LEN = 256\n",
    "\n",
    "def convert_sents_ids(sentences):\n",
    "    ids = []\n",
    "    for word in tqdm(sentences):\n",
    "        subwords = '<s> ' + bpe.encode(word) + ' </s>'\n",
    "        encoded_sentence = vocab.encode_line(subwords, append_eos=True, add_if_not_exist=False).long().tolist()\n",
    "        ids.append(encoded_sentence)\n",
    "    ids = pad_sequences(ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
    "    return torch.tensor(ids)\n",
    "\n",
    "X_train_ids = convert_sents_ids(X_train)\n",
    "X_val_ids = convert_sents_ids(X_val)\n",
    "X_test_ids = convert_sents_ids(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6c0a470",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T08:40:12.496713Z",
     "iopub.status.busy": "2024-03-07T08:40:12.496329Z",
     "iopub.status.idle": "2024-03-07T08:40:12.504018Z",
     "shell.execute_reply": "2024-03-07T08:40:12.502939Z"
    },
    "papermill": {
     "duration": 0.330626,
     "end_time": "2024-03-07T08:40:12.505941",
     "exception": false,
     "start_time": "2024-03-07T08:40:12.175315",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1910\n",
      "256\n",
      "tensor([    0, 31553, 10157,   227, 17308,  5841,   976, 44495,    35,     9,\n",
      "         1148, 12116,     4,  7725,   120,   298,   136,   403,   197,  1061,\n",
      "            5,  3478,     9,  1148,   131,  2784,   185,   170,    40,    25,\n",
      "          185,   280, 12901,    80,    95,   228,     4,    12,    26,    37,\n",
      "          525,    18,    30,   188,    32, 17922,   976,     5,    22,  1584,\n",
      "           72,    84,   204,   283,    32,   667,   170,    11,    36,     5,\n",
      "         2820,     4,   523,  8417, 56756,  1175,   544,    38,  2388,    24,\n",
      "         1269,   133,   228,    77,    21,    18,  7625,   403, 18295,    48,\n",
      "           22,     4,   286,    16,  1148, 12116,    34,   835, 14060,  1992,\n",
      "           15,  7597,     5,   157,    13,    55,     4,   525, 10157,   170,\n",
      "           40,    12,    43,  2402,    35,  1148,    83,   644,    50,   474,\n",
      "           48,   246,    15, 10673,     5,    22,   319,   311,    36,    26,\n",
      "          283,   170,    75,  7895,   781,   824,     4,  8632,  2402,    66,\n",
      "        42603,  4709,   228,     8,    81,    22,     4,    83,  2497,     5,\n",
      "           79,    83,     4,   681,  7625, 10157,  3792,    59,  4064,     6,\n",
      "         1082,  1401,  4458,  4103,     7,  1175,  9606,     5,    22, 44495,\n",
      "           35,   610,   298,   136,  6650,   307,    50,  7576, 27511,    80,\n",
      "            4,   474,    48,   225,    75,   119,   877,    80,     5,  4978,\n",
      "        13773, 10099,    64,  1896,    33,  1997,    24, 14361,    22,     4,\n",
      "           83,  1833,     5,  1584,   786,    35,    36,  5389,   329, 12116,\n",
      "           85,    34,   835, 36286,    20,   189,    11,   305,     8,   591,\n",
      "         2553, 12116,     4,  4103,    25,   120,    19,   298,   136,     8,\n",
      "         7576,  1551, 36862,  7576, 36184,    80,    95,   228,    20,   188,\n",
      "           33,    31,   170,    40,    19,     4,   197,   124,   978,    80,\n",
      "           95,   228,   246,    15,   129,   317,   386,    71,     5,  2467,\n",
      "          756,     8,  7233, 10157,    52,   430])\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train[0]))\n",
    "print(len(X_train_ids[0]))\n",
    "print(X_train_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1c4947",
   "metadata": {
    "papermill": {
     "duration": 0.318511,
     "end_time": "2024-03-07T08:40:13.141975",
     "exception": false,
     "start_time": "2024-03-07T08:40:12.823464",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Tạo dataloader từ text và labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79955e66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T08:40:13.826716Z",
     "iopub.status.busy": "2024-03-07T08:40:13.825845Z",
     "iopub.status.idle": "2024-03-07T08:40:13.833262Z",
     "shell.execute_reply": "2024-03-07T08:40:13.832396Z"
    },
    "papermill": {
     "duration": 0.330263,
     "end_time": "2024-03-07T08:40:13.835198",
     "exception": false,
     "start_time": "2024-03-07T08:40:13.504935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "\n",
    "def make_data_loader(ids, labels, BATCH_SIZE=32):\n",
    "    labels = torch.tensor(labels)\n",
    "    dataset = TensorDataset(ids, labels)\n",
    "#     sampler = SequentialSampler(data)\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True) \n",
    "    return dataloader\n",
    "\n",
    "\n",
    "train_dataloader = make_data_loader(X_train_ids, y_train)\n",
    "val_dataloader = make_data_loader(X_val_ids, y_val)\n",
    "test_dataloader = make_data_loader(X_test_ids, label_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75163d63",
   "metadata": {
    "papermill": {
     "duration": 0.313834,
     "end_time": "2024-03-07T08:40:14.466429",
     "exception": false,
     "start_time": "2024-03-07T08:40:14.152595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load model PhoBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4b0e05f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T08:40:15.102875Z",
     "iopub.status.busy": "2024-03-07T08:40:15.102039Z",
     "iopub.status.idle": "2024-03-07T08:40:25.996400Z",
     "shell.execute_reply": "2024-03-07T08:40:25.995317Z"
    },
    "papermill": {
     "duration": 11.213761,
     "end_time": "2024-03-07T08:40:25.998441",
     "exception": false,
     "start_time": "2024-03-07T08:40:14.784680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading codes from PhoBERT_base_fairseq/bpe.codes ...\n",
      "Read 64000 codes from the codes file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaForSequenceClassification, RobertaConfig\n",
    "\n",
    "NUM_LABELS = len(lb_encoder.classes_)\n",
    "from fairseq.models.roberta import RobertaModel\n",
    "pho_bert = RobertaModel.from_pretrained('PhoBERT_base_fairseq', checkpoint_file='model.pt')\n",
    "\n",
    "pho_bert.register_classification_head('new_task', num_classes=NUM_LABELS)\n",
    "\n",
    "class BPE():\n",
    "    bpe_codes = 'PhoBERT_base_fairseq/bpe.codes'\n",
    "\n",
    "args = BPE()\n",
    "pho_bert.bpe = fastBPE(args)\n",
    "\n",
    "pho_bert.cuda()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb219ad4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T08:40:26.641289Z",
     "iopub.status.busy": "2024-03-07T08:40:26.640386Z",
     "iopub.status.idle": "2024-03-07T08:40:26.646771Z",
     "shell.execute_reply": "2024-03-07T08:40:26.645864Z"
    },
    "papermill": {
     "duration": 0.327766,
     "end_time": "2024-03-07T08:40:26.648604",
     "exception": false,
     "start_time": "2024-03-07T08:40:26.320838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def evaluate(logits, targets):\n",
    "    \"\"\"\n",
    "    Đánh giá model sử dụng accuracy và f1 scores.\n",
    "    Args:\n",
    "        logits (B,C): torch.LongTensor. giá trị predicted logit cho class output.\n",
    "        targets (B): torch.LongTensor. actual target indices.\n",
    "    Returns:\n",
    "        acc (float): the accuracy score\n",
    "        f1 (float): the f1 score\n",
    "    \"\"\"\n",
    "    # Tính accuracy score và f1_score\n",
    "    logits = logits.detach().cpu().numpy()    \n",
    "    y_pred = np.argmax(logits, axis = 1)\n",
    "    targets = targets.detach().cpu().numpy()\n",
    "    f1 = f1_score(targets, y_pred, average='weighted')\n",
    "    acc = accuracy_score(targets, y_pred)\n",
    "    return acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc7ee607",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T08:40:27.348239Z",
     "iopub.status.busy": "2024-03-07T08:40:27.347761Z",
     "iopub.status.idle": "2024-03-07T09:42:44.854924Z",
     "shell.execute_reply": "2024-03-07T09:42:44.853957Z"
    },
    "papermill": {
     "duration": 3737.84698,
     "end_time": "2024-03-07T09:42:44.857609",
     "exception": false,
     "start_time": "2024-03-07T08:40:27.010629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- Epochs 1 -----------------\n",
      "Trainning ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "950it [12:02,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.9001\n",
      " F1 score: 0.8973\n",
      " Average training loss: 0.3425\n",
      "Running Validation ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [00:24<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.9233\n",
      " F1 score: 0.9215\n",
      "------------- Epochs 2 -----------------\n",
      "Trainning ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "950it [12:02,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.9508\n",
      " F1 score: 0.9507\n",
      " Average training loss: 0.1535\n",
      "Running Validation ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [00:24<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.9272\n",
      " F1 score: 0.9266\n",
      "------------- Epochs 3 -----------------\n",
      "Trainning ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "950it [12:03,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.9690\n",
      " F1 score: 0.9690\n",
      " Average training loss: 0.1007\n",
      "Running Validation ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [00:24<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.9337\n",
      " F1 score: 0.9338\n",
      "------------- Epochs 4 -----------------\n",
      "Trainning ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "950it [12:03,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.9804\n",
      " F1 score: 0.9804\n",
      " Average training loss: 0.0663\n",
      "Running Validation ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [00:24<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.9287\n",
      " F1 score: 0.9285\n",
      "------------- Epochs 5 -----------------\n",
      "Trainning ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "950it [12:03,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.9866\n",
      " F1 score: 0.9866\n",
      " Average training loss: 0.0463\n",
      "Running Validation ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [00:24<00:00,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.9269\n",
      " F1 score: 0.9268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "criteria = torch.nn.NLLLoss()\n",
    "\n",
    "device = 'cuda'\n",
    "epochs = 5\n",
    "\n",
    "param_optimizer = list(pho_bert.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "    'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "    'weight_decay': 0},\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5, correct_bias=False)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'------------- Epochs {epoch + 1} -----------------')\n",
    "    print('Trainning ...')\n",
    "    pho_bert.train()\n",
    "    sum_loss = 0\n",
    "    sum_acc = 0\n",
    "    sum_f1 = 0\n",
    "    nb_train_steps = 0\n",
    "    \n",
    "    for i, (x_batch, y_batch) in tqdm(enumerate(train_dataloader)):\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_preds = pho_bert.predict('new_task', x_batch)\n",
    "        logits = torch.exp(y_preds)\n",
    "        acc, f1 = evaluate(logits, y_batch)\n",
    "        loss = criteria(y_preds, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_val = loss.item()\n",
    "        sum_loss += loss_val\n",
    "        sum_acc += acc \n",
    "        sum_f1 += f1\n",
    "        nb_train_steps += 1\n",
    "    \n",
    "    avg_train_loss = sum_loss / len(train_dataloader)\n",
    "    \n",
    "    print(\" Accuracy: {0:.4f}\".format(sum_acc/nb_train_steps))\n",
    "    print(\" F1 score: {0:.4f}\".format(sum_f1/nb_train_steps))\n",
    "    print(\" Average training loss: {0:.4f}\".format(avg_train_loss))\n",
    "    \n",
    "    print('Running Validation ...')\n",
    "    \n",
    "    pho_bert.eval()\n",
    "    accs = []\n",
    "    f1s = []\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in tqdm(val_dataloader):\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            outputs = pho_bert.predict('new_task', x_batch)\n",
    "            logits = torch.exp(outputs)\n",
    "            acc, f1 = evaluate(logits, y_batch)\n",
    "            accs.append(acc)\n",
    "            f1s.append(f1)\n",
    "    mean_acc = np.mean(accs)\n",
    "    mean_f1 = np.mean(f1s) \n",
    "     \n",
    "    print(\" Accuracy: {0:.4f}\".format(mean_acc))  \n",
    "    print(\" F1 score: {0:.4f}\".format(mean_f1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "963e6d5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T09:42:46.327950Z",
     "iopub.status.busy": "2024-03-07T09:42:46.327585Z",
     "iopub.status.idle": "2024-03-07T09:48:51.203057Z",
     "shell.execute_reply": "2024-03-07T09:48:51.201907Z"
    },
    "papermill": {
     "duration": 365.609733,
     "end_time": "2024-03-07T09:48:51.206691",
     "exception": false,
     "start_time": "2024-03-07T09:42:45.596958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1575/1575 [06:04<00:00,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.86      7567\n",
      "           1       0.76      0.42      0.54      2036\n",
      "           2       0.78      0.83      0.80      2096\n",
      "           3       0.93      0.88      0.90      5276\n",
      "           4       0.87      0.94      0.90      3788\n",
      "           5       0.92      0.94      0.93      5417\n",
      "           6       0.93      0.94      0.93      6716\n",
      "           7       0.98      0.99      0.98      6667\n",
      "           8       0.90      0.97      0.93      6250\n",
      "           9       0.93      0.96      0.94      4560\n",
      "\n",
      "    accuracy                           0.91     50373\n",
      "   macro avg       0.89      0.87      0.87     50373\n",
      "weighted avg       0.90      0.91      0.90     50373\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def test(dataloader): \n",
    "    pho_bert.eval()\n",
    "    loss, acc, f1 = 0, 0, 0\n",
    "    predicts = []\n",
    "    real_values = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in tqdm(dataloader):\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            outputs = pho_bert.predict('new_task', x_batch)\n",
    "            logits = torch.exp(outputs)\n",
    "            acc, f1 = evaluate(logits, y_batch)\n",
    "            accs.append(acc)\n",
    "            f1s.append(f1)\n",
    "            \n",
    "            logits = logits.detach().cpu().numpy()    \n",
    "            predicts.append(np.argmax(logits, axis = 1))\n",
    "            real_values.append(y_batch.detach().cpu().numpy())\n",
    "            \n",
    "    predicts = np.concatenate(predicts)\n",
    "    real_values = np.concatenate(real_values)\n",
    "\n",
    "    print('\\n', classification_report(real_values, predicts))\n",
    "    \n",
    "test(test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5881.013871,
   "end_time": "2024-03-07T09:48:55.124669",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-07T08:10:54.110798",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
